{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'modules'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4be9bd1e919c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'modules'"
     ]
    }
   ],
   "source": [
    "import pandas as df\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import modules.utils as utils\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Directory = 'data'\n",
    "u_ds = utils.concatenate_time(Directory, 'u')\n",
    "v_ds = utils.concatenate_time(Directory, 'v')\n",
    "w_ds = utils.concatenate_time(Directory, 'w')\n",
    "theta_ds = utils.concatenate_time(Directory, 'theta')\n",
    "assert u_ds.shape == v_ds.shape == w_ds.shape == theta_ds.shape, 'u,v,w,theta have different shape'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtheta_ds = w_ds*theta_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coarse_array(ds, L):\n",
    "    '''\n",
    "    ## Description\n",
    "    Coarsen a dataset over the altitude and time axis.\n",
    "    The new shape is (time, altitude, y, x) where y and x are divided by L.\n",
    "\n",
    "    ## Parameters\n",
    "    - ds (np array) : dataset to coarsen\n",
    "    - L (int) : coarsening factor\n",
    "    '''\n",
    "    #initialize coarse array\n",
    "    coarse_ds = np.zeros((ds.shape[0], ds.shape[1], int(ds.shape[2]/L), int(ds.shape[3]/L)))\n",
    "    for t in range(ds.shape[0]):\n",
    "        for z in range(ds.shape[1]):\n",
    "            for i in range(int(ds.shape[2]/L)):\n",
    "                for j in range(int(ds.shape[3]/L)):\n",
    "                    coarse_ds[t,z,i,j] = np.mean(ds[t,z,i*L:(i+1)*L,j*L:(j+1)*L])\n",
    "    return coarse_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 16, 16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_coarse = utils.coarse_array(u_ds, 32)\n",
    "u_coarse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vector of altitudes for each y,x point\n",
    "u_samples = np.zeros((u_coarse.shape[0]*u_coarse.shape[2]*u_coarse.shape[3], u_coarse.shape[1]))\n",
    "\n",
    "for t in range(u_coarse.shape[0]):\n",
    "    for i in range(u_coarse.shape[2]):\n",
    "        for j in range(u_coarse.shape[3]):\n",
    "            u_samples[t*u_coarse.shape[2]*u_coarse.shape[3] + i*u_coarse.shape[3] + j] = u_coarse[t,:,i,j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_samples(ds,L):\n",
    "    '''\n",
    "    ## Description\n",
    "    Get the samples of a dataset over the altitude axis.\n",
    "    The new shape is (time, y, x) where y and x are divided by L.\n",
    "\n",
    "    ## Parameters\n",
    "    - ds (np array) : dataset to coarsen\n",
    "    - L (int) : coarsening factor\n",
    "    '''\n",
    "    #initialize coarse array\n",
    "    ds_coarse = coarse_array(ds, L)\n",
    "    samples = np.zeros((ds_coarse.shape[0]*ds_coarse.shape[2]*ds_coarse.shape[3], ds_coarse.shape[1]))\n",
    "    for t in range(ds_coarse.shape[0]):\n",
    "        for i in range(ds_coarse.shape[2]):\n",
    "            for j in range(ds_coarse.shape[3]):\n",
    "                samples[t*ds_coarse.shape[2]*ds_coarse.shape[3] + i*ds_coarse.shape[3] + j] = ds_coarse[t,:,i,j]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.9804707 , 14.99043066, 15.00086523, 15.00930762],\n",
       "       [14.8064375 , 14.82397559, 14.84153613, 14.8614502 ],\n",
       "       [14.9475625 , 14.96709766, 14.98912402, 15.0123125 ],\n",
       "       ...,\n",
       "       [14.7393252 , 14.75418555, 14.76291113, 14.76828418],\n",
       "       [14.69826953, 14.71771484, 14.73111426, 14.7410918 ],\n",
       "       [14.42030859, 14.43687695, 14.45350586, 14.46567773]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.variable_samples(u_ds, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_dataset(dir,variables,L):\n",
    "    '''\n",
    "    ## Description\n",
    "    Create a dataset of the variables in the list variables.\n",
    "    The new shape is (time*y*x, altitude*nbvar).\n",
    "\n",
    "    ## Parameters\n",
    "    - dir (str) : directory where the data is stored\n",
    "    - variables (list) : list of variables to include in the dataset\n",
    "    - L (int) : coarsening factor\n",
    "    '''\n",
    "    l = len(variables)\n",
    "    assert l!=0, 'variables list is empty'\n",
    "    #initialize dataset\n",
    "    ds = var_samples(utils.concatenate_time(dir, variables[0]), L)\n",
    "    for var in range(1,l):\n",
    "        ds = np.concatenate((ds,var_samples(utils.concatenate_time(dir, variables[var]),L)), axis=1)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['u', 'v', 'w', 'theta']\n",
    "input_ds = utils.input_dataset(Directory, variables, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ds = utils.variable_samples(wtheta_ds, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 20)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_ds = np.concatenate((input_ds, output_ds), axis=1)\n",
    "tot_ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a three layer linear neural network with one hidden layer, input size is 16 and output size is 4\n",
    "class LinNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LinNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "learning_rate = 0.001\n",
    "model = LinNet(16,32,4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 16)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split input_ds and output_ds into training and validation sets\n",
    "train, test = utils.split_train_val(tot_ds)\n",
    "input_train, output_train, input_val, output_val = train[:,:16], train[:,16:], test[:,:16], test[:,16:]\n",
    "input_val.shape\n",
    "#tot_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9449, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.from_numpy(input_train).float()\n",
    "output = torch.from_numpy(output_train).float()\n",
    "input_batch = input[batch_size:2*batch_size,:]\n",
    "output_batch = output[batch_size:2*batch_size,:]\n",
    "F.mse_loss(model(input_batch), output_batch, reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 3.018055\n",
      "Epoch [20/100], Loss: 2.579090\n",
      "Epoch [30/100], Loss: 2.054344\n",
      "Epoch [40/100], Loss: 1.196923\n",
      "Epoch [50/100], Loss: 0.195739\n",
      "Epoch [60/100], Loss: 0.025092\n",
      "Epoch [70/100], Loss: 0.006778\n",
      "Epoch [80/100], Loss: 0.005000\n",
      "Epoch [90/100], Loss: 0.003864\n",
      "Epoch [100/100], Loss: 0.003124\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "nb_epochs = 100\n",
    "losses=[]\n",
    "batch_size = 32\n",
    "model.train()\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "    tot_losses=0\n",
    "    for i in np.random.permutation(input_train.shape[0]//batch_size):\n",
    "        # convert numpy array to torch tensor\n",
    "        input = torch.from_numpy(input_train).float()\n",
    "        output = torch.from_numpy(output_train).float()\n",
    "        loss=0\n",
    "\n",
    "        input_batch = input[i*batch_size:(i+1)*batch_size,:]\n",
    "        output_batch = output[i*batch_size:(i+1)*batch_size,:]\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        output_pred = model(input_batch)\n",
    "        # compute loss\n",
    "        loss += F.mse_loss(output_pred, output_batch, reduction='sum')\n",
    "        tot_losses += loss.item()\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    losses.append(tot_losses/(input_train.shape[0]//batch_size))\n",
    "    if (epoch+1)%10==0:\n",
    "        print('Epoch [{}/{}], Loss: {:.6f}'.format(epoch+1, nb_epochs, tot_losses/(input_train.shape[0]//batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f932ffe8640>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.003003\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "\n",
    "# convert numpy array to torch tensor\n",
    "input_test = torch.from_numpy(input_val).float()\n",
    "output_test = torch.from_numpy(output_val).float()\n",
    "predictions= torch.zeros(output_test.shape)\n",
    "tot_losses=0\n",
    "\n",
    "model.eval()\n",
    "# prediction\n",
    "output_pred = model(input_test)\n",
    "# compute loss\n",
    "loss = F.mse_loss(output_pred, output_test, reduction='sum')\n",
    "\n",
    "print('Test loss: {:.6f}'.format(loss*batch_size/input_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1718, -0.1762, -0.1793, -0.1852],\n",
      "        [-0.1489, -0.1460, -0.1535, -0.1595],\n",
      "        [-0.0096, -0.0031, -0.0083, -0.0073],\n",
      "        [-0.0275, -0.0156, -0.0251, -0.0280],\n",
      "        [-0.1305, -0.1288, -0.1351, -0.1352]], grad_fn=<SliceBackward>)\n",
      "tensor([[-0.1735, -0.1757, -0.1778, -0.1801],\n",
      "        [-0.1394, -0.1469, -0.1540, -0.1610],\n",
      "        [-0.0024, -0.0060, -0.0095, -0.0128],\n",
      "        [-0.0281, -0.0260, -0.0238, -0.0213],\n",
      "        [-0.1238, -0.1304, -0.1370, -0.1435]])\n"
     ]
    }
   ],
   "source": [
    "print(output_pred[:5])\n",
    "print(output_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a three layer convolutional neural network with one hidden layer, input size is 16 and output size is 4\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(in_features=64, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        #x = x.view(-1, 64*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2126593c4ba056f374a5f953e7ab3e7ee968bf458a40de64ddebe48ce9256529"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
