{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as df\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir(Path(sys.path[0]).parent)\n",
    "import modules.utils as utils\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Directory = 'data'\n",
    "u_ds = utils.concatenate_time(Directory, 'u')\n",
    "v_ds = utils.concatenate_time(Directory, 'v')\n",
    "w_ds = utils.concatenate_time(Directory, 'w')\n",
    "theta_ds = utils.concatenate_time(Directory, 'theta')\n",
    "assert u_ds.shape == v_ds.shape == w_ds.shape == theta_ds.shape, 'u,v,w,theta have different shape'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtheta_ds = w_ds*theta_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 16, 16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_coarse = utils.coarse_array(u_ds, 32)\n",
    "v_coarse = utils.coarse_array(v_ds, 32)\n",
    "w_coarse = utils.coarse_array(w_ds, 32)\n",
    "u_coarse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 16, 16)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tke_ds = utils.coarse_array(u_ds*u_ds, 32) - u_coarse*u_coarse + utils.coarse_array(v_ds*v_ds, 32) - v_coarse*v_coarse + utils.coarse_array(w_ds*w_ds, 32) - w_coarse*w_coarse\n",
    "tke_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vector of altitudes for each y,x point\n",
    "u_samples = np.zeros((u_coarse.shape[0]*u_coarse.shape[2]*u_coarse.shape[3], u_coarse.shape[1]))\n",
    "\n",
    "for t in range(u_coarse.shape[0]):\n",
    "    for i in range(u_coarse.shape[2]):\n",
    "        for j in range(u_coarse.shape[3]):\n",
    "            u_samples[t*u_coarse.shape[2]*u_coarse.shape[3] + i*u_coarse.shape[3] + j] = u_coarse[t,:,i,j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.variable_samples(u_ds, 32).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['u', 'v', 'w', 'theta']  # add 's' \n",
    "input_ds = utils.input_dataset(Directory, variables, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 16)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tke_in = utils.variable_samples(tke_ds, 1)\n",
    "output_ds = utils.variable_samples(wtheta_ds, 32)\n",
    "tke_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 24)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_ds = np.concatenate((np.concatenate((input_ds,tke_in), axis=1), output_ds), axis=1)\n",
    "tot_ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a three layer linear neural network with one hidden layer, input size is 16 and output size is 4\n",
    "class LinNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LinNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "learning_rate = 0.001\n",
    "model = LinNet(20,32,4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 20)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split input_ds and output_ds into training and validation sets\n",
    "train, test = utils.split_train_val(tot_ds,32)\n",
    "input_train, output_train, input_val, output_val = train[:,:20], train[:,20:], test[:,:20], test[:,20:]\n",
    "input_val.shape\n",
    "#tot_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9449, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.from_numpy(input_train).float()\n",
    "output = torch.from_numpy(output_train).float()\n",
    "input_batch = input[batch_size:2*batch_size,:]\n",
    "output_batch = output[batch_size:2*batch_size,:]\n",
    "F.mse_loss(model(input_batch), output_batch, reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 2.651362\n",
      "Epoch [20/100], Loss: 1.909033\n",
      "Epoch [30/100], Loss: 1.428063\n",
      "Epoch [40/100], Loss: 0.829636\n",
      "Epoch [50/100], Loss: 0.516530\n",
      "Epoch [60/100], Loss: 0.379457\n",
      "Epoch [70/100], Loss: 0.322395\n",
      "Epoch [80/100], Loss: 0.259224\n",
      "Epoch [90/100], Loss: 0.224755\n",
      "Epoch [100/100], Loss: 0.218070\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "nb_epochs = 100\n",
    "losses=[]\n",
    "batch_size = 32\n",
    "model.train()\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "    tot_losses=0\n",
    "    for i in np.random.permutation(input_train.shape[0]//batch_size):\n",
    "        # convert numpy array to torch tensor\n",
    "        input = torch.from_numpy(input_train).float()\n",
    "        output = torch.from_numpy(output_train).float()\n",
    "        loss=0\n",
    "\n",
    "        input_batch = input[i*batch_size:(i+1)*batch_size,:]\n",
    "        output_batch = output[i*batch_size:(i+1)*batch_size,:]\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        output_pred = model(input_batch)\n",
    "        # compute loss\n",
    "        loss += F.mse_loss(output_pred, output_batch, reduction='sum')\n",
    "        tot_losses += loss.item()\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    losses.append(tot_losses/(input_train.shape[0]//batch_size))\n",
    "    if (epoch+1)%10==0:\n",
    "        print('Epoch [{}/{}], Loss: {:.6f}'.format(epoch+1, nb_epochs, tot_losses/(input_train.shape[0]//batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbf49c49e20>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.190213\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "\n",
    "# convert numpy array to torch tensor\n",
    "input_test = torch.from_numpy(input_val).float()\n",
    "output_test = torch.from_numpy(output_val).float()\n",
    "predictions= torch.zeros(output_test.shape)\n",
    "tot_losses=0\n",
    "\n",
    "model.eval()\n",
    "# prediction\n",
    "output_pred = model(input_test)\n",
    "# compute loss\n",
    "loss = F.mse_loss(output_pred, output_test, reduction='sum')\n",
    "\n",
    "print('Test loss: {:.6f}'.format(loss*batch_size/input_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2030, 0.2359, 0.2534, 0.2327],\n",
      "        [0.2530, 0.2538, 0.2637, 0.2726],\n",
      "        [0.3081, 0.2995, 0.2957, 0.3282],\n",
      "        [0.2327, 0.2537, 0.2437, 0.2612],\n",
      "        [0.1599, 0.1813, 0.1876, 0.1819]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1177, 0.1207, 0.1238, 0.1267],\n",
      "        [0.2500, 0.2542, 0.2579, 0.2616],\n",
      "        [0.3858, 0.3905, 0.3950, 0.3996],\n",
      "        [0.2752, 0.2856, 0.2963, 0.3070],\n",
      "        [0.1327, 0.1382, 0.1438, 0.1497]])\n"
     ]
    }
   ],
   "source": [
    "print(output_pred[-5:])\n",
    "print(output_test[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2126593c4ba056f374a5f953e7ab3e7ee968bf458a40de64ddebe48ce9256529"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
